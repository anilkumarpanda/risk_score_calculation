{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime as dt\n",
    "#import datetime as datetime\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv',sep=',')\n",
    "dataset.head()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def getStdDate(x):\n",
    "    dt_list = x.split('/')\n",
    "    #dt_str = \"0\"+dt_list[0]+\"/\"+\"0\"+dt_list[1]+\"/\"+dt_list[2]\n",
    "    dt_str = dt_list[2]+\"-\"+\"0\"+dt_list[0]+\"-\"+dt_list[1]\n",
    "    datetime_object = dt.datetime.strptime(dt_str,'%Y-%m-%d')\n",
    "    return datetime_object\n",
    "\n",
    "dataset['creationdate'] = dataset['creationdate'].apply(lambda x : getStdDate(x))\n",
    "today= dt.datetime.today().strftime('%Y-%m-%d')\n",
    "today= pd.to_datetime(today)\n",
    "\n",
    "dataset['recency'] = dataset['creationdate'].apply(lambda x:(1/(today-x).days)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_count = dataset['bin'].value_counts()\n",
    "bin_count_pdf = bin_count.to_frame()\n",
    "bin_count_pdf['count_of_txn'] = bin_count_pdf['bin']\n",
    "bin_count_pdf['bin'] = bin_count_pdf.index\n",
    "bin_count_pdf.sort_values(by='bin').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAHjCAYAAADPOQ0nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f198668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.xlabel(\"Fraud Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(True)\n",
    "plt.hist(dataset['fraud'],log=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sub = dataset[['bin','fraud']]\n",
    "dataset_sub_pdf = dataset_sub.groupby([\"bin\"]).sum().reset_index()\n",
    "dataset_sub_pdf.sort_values(by='bin').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_fraud_pdf = bin_count_pdf.merge(dataset_sub_pdf, left_on='bin', right_on='bin', how='inner')\n",
    "bin_fraud_pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_fraud_pdf['pc_fraud']=bin_fraud_pdf['fraud']/bin_fraud_pdf['count_of_txn']\n",
    "bin_fraud_pdf.sort_values(by='pc_fraud').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_fraud_pdf= bin_fraud_pdf.rename(columns={\"fraud\": \"fraud_count\"})\n",
    "bin_fraud_pdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(bin_fraud_pdf, left_on='bin', right_on='bin', how='inner')\n",
    "dataset = dataset.drop_duplicates()\n",
    "print(\"Shape after join \",dataset.shape)\n",
    "\n",
    "#drop_list = ['creationdate','bin','count_of_txn','fraud_count']\n",
    "drop_list = ['creationdate','bin','fraud_refusal','declined','count_of_txn','fraud_count']\n",
    "dataset = dataset.drop(drop_list,axis=1)\n",
    "\n",
    "y_col = 'fraud'\n",
    "X = dataset.drop(y_col,axis=1)\n",
    "dataset['amount'] = dataset['amount'].apply(lambda x : np.log(x+1))\n",
    "y = dataset['fraud']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# vc_list = ['amount', 'fraud_refusal', 'declined', 'rule_3', 'rule_4', 'rule_7', 'rule_8', 'rule_9', 'rule_11', 'rule_22', 'rule_26', 'rule_47', 'rule_49', 'rule_50', 'rule_51', 'rule_52', 'rule_63', 'rule_66', 'rule_74', 'rule_77']\n",
    "# chi2_list = ['amount', 'fraud_refusal', 'declined', 'rule_3', 'rule_4', 'rule_8', 'rule_9', 'rule_11', 'rule_22', 'rule_26', 'rule_49', 'rule_55', 'rule_63', 'rule_64', 'rule_74']\n",
    "# f_classify_list = ['amount', 'fraud_refusal', 'declined', 'rule_3', 'rule_4', 'rule_8', 'rule_9', 'rule_11', 'rule_22', 'rule_26', 'rule_49', 'rule_55', 'rule_63', 'rule_64', 'rule_74']\n",
    "# mir_list = ['rule_7', 'rule_13', 'rule_25', 'rule_28', 'rule_30', 'rule_34', 'rule_35', 'rule_37', 'rule_39', 'rule_49', 'rule_52', 'rule_54', 'rule_56', 'rule_68', 'rule_77']\n",
    "\n",
    "vc_list = ['amount', 'rule_3', 'rule_4', 'rule_7', 'rule_8', 'rule_9', 'rule_11', 'rule_22', 'rule_26', 'rule_47', 'rule_49', 'rule_50', 'rule_51', 'rule_52', 'rule_63', 'rule_66', 'rule_74', 'rule_77']\n",
    "chi2_list = ['amount', 'rule_3', 'rule_4', 'rule_8', 'rule_9', 'rule_11', 'rule_22', 'rule_26', 'rule_49', 'rule_55', 'rule_63', 'rule_64', 'rule_74']\n",
    "f_classify_list = ['amount', 'rule_3', 'rule_4', 'rule_8', 'rule_9', 'rule_11', 'rule_22', 'rule_26', 'rule_49', 'rule_55', 'rule_63', 'rule_64', 'rule_74']\n",
    "mir_list = ['rule_7', 'rule_13', 'rule_25', 'rule_28', 'rule_30', 'rule_34', 'rule_35', 'rule_37', 'rule_39', 'rule_49', 'rule_52', 'rule_54', 'rule_56', 'rule_68', 'rule_77']\n",
    "\n",
    "\n",
    "var_sel = []\n",
    "var_sel = var_sel+vc_list\n",
    "var_sel = var_sel+chi2_list\n",
    "var_sel = var_sel+f_classify_list\n",
    "var_sel = var_sel+mir_list\n",
    "\n",
    "X = X[ X.columns.intersection(var_sel)]\n",
    "y = y\n",
    "\n",
    "# scaler = StandardScaler().fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# scaler = Normalizer().fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "target_names = ['0','1']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "colors = ['navy', 'red']\n",
    "lw = 2\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of Fraud dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_r,y,train_size=0.75,test_size=0.25)\n",
    "\n",
    "tpot = TPOTClassifier(generations=5,population_size=50,verbosity=2,scoring='f1_weighted',n_jobs=48)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_fraud_pca.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "\n",
    "def plot_resampling(ax, X, y, title):\n",
    "    c0 = ax.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.5)\n",
    "    c1 = ax.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([-6, 8])\n",
    "    ax.set_ylim([-6, 6])\n",
    "\n",
    "    return c0, c1\n",
    "\n",
    "\n",
    "# # Generate the dataset\n",
    "# X, y = make_classification(n_classes=2, class_sep=2, weights=[0.3, 0.7],\n",
    "#                            n_informative=3, n_redundant=1, flip_y=0,\n",
    "#                            n_features=20, n_clusters_per_class=1,\n",
    "#                            n_samples=80, random_state=10)\n",
    "\n",
    "# Instanciate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components=2)\n",
    "# Fit and transform x to visualise inside a 2D feature space\n",
    "X_vis = pca.fit_transform(X)\n",
    "\n",
    "# Apply regular SMOTE\n",
    "#kind = ['regular', 'borderline1', 'borderline2', 'svm']\n",
    "kind = ['regular']\n",
    "\n",
    "sm = [SMOTE(kind=k) for k in kind]\n",
    "X_resampled = []\n",
    "y_resampled = []\n",
    "X_res_vis = []\n",
    "for method in sm:\n",
    "    X_res, y_res = method.fit_sample(X, y)\n",
    "    X_resampled.append(X_res)\n",
    "    y_resampled.append(y_res)\n",
    "    X_res_vis.append(pca.transform(X_res))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "# Two subplots, unpack the axes array immediately\n",
    "f, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2)\n",
    "# Remove axis for second plot\n",
    "ax2.axis('off')\n",
    "ax_res = [ax3, ax4, ax5, ax6]\n",
    "\n",
    "c0, c1 = plot_resampling(ax1, X_vis, y, 'Original set')\n",
    "for i in range(len(kind)):\n",
    "    plot_resampling(ax_res[i], X_res_vis[i], y_resampled[i],\n",
    "                    'SMOTE {}'.format(kind[i]))\n",
    "\n",
    "ax2.legend((c0, c1), ('Class #0', 'Class #1'), loc='center',\n",
    "           ncol=1, labelspacing=0.)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# Instanciate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components=2)\n",
    "# Fit and transform x to visualise inside a 2D feature space\n",
    "X_vis = pca.fit_transform(X)\n",
    "\n",
    "# Apply the random over-sampling\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_sample(X, y)\n",
    "X_res_vis = pca.transform(X_resampled)\n",
    "\n",
    "# Two subplots, unpack the axes array immediately\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "c0 = ax1.scatter(X_vis[y == 0, 0], X_vis[y == 0, 1], label=\"Class #0\",\n",
    "                 alpha=0.5)\n",
    "c1 = ax1.scatter(X_vis[y == 1, 0], X_vis[y == 1, 1], label=\"Class #1\",\n",
    "                 alpha=0.5)\n",
    "ax1.set_title('Original set')\n",
    "\n",
    "\n",
    "ax2.scatter(X_res_vis[y_resampled == 0, 0], X_res_vis[y_resampled == 0, 1],\n",
    "            label=\"Class #0\", alpha=.5)\n",
    "ax2.scatter(X_res_vis[y_resampled == 1, 0], X_res_vis[y_resampled == 1, 1],\n",
    "            label=\"Class #1\", alpha=.5)\n",
    "ax2.set_title('Random over-sampling')\n",
    "\n",
    "# make nice plotting\n",
    "for ax in (ax1, ax2):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([-6, 8])\n",
    "    ax.set_ylim([-6, 6])\n",
    "\n",
    "\n",
    "\n",
    "plt.figlegend((c0, c1), ('Class #0', 'Class #1'), loc='lower center',\n",
    "              ncol=2, labelspacing=0.)\n",
    "plt.tight_layout(pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import datasets, metrics, tree\n",
    "\n",
    "from imblearn import over_sampling as os\n",
    "from imblearn import pipeline as pl\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "scorer = metrics.make_scorer(metrics.cohen_kappa_score)\n",
    "\n",
    "# # Generate the dataset\n",
    "# X, y = datasets.make_classification(n_classes=2, class_sep=2,\n",
    "#                                     weights=[0.1, 0.9], n_informative=10,\n",
    "#                                     n_redundant=1, flip_y=0, n_features=20,\n",
    "#                                     n_clusters_per_class=4, n_samples=5000,\n",
    "#                                     random_state=RANDOM_STATE)\n",
    "smote = os.SMOTE(random_state=RANDOM_STATE)\n",
    "cart = tree.DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "pipeline = pl.make_pipeline(smote, cart)\n",
    "\n",
    "param_range = range(1, 11)\n",
    "train_scores, test_scores = ms.validation_curve(\n",
    "    pipeline, X, y, param_name=\"smote__k_neighbors\", param_range=param_range,\n",
    "    cv=3, scoring=scorer, n_jobs=1)\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "plt.plot(param_range, test_scores_mean, label='SMOTE')\n",
    "ax.fill_between(param_range, test_scores_mean + test_scores_std,\n",
    "                test_scores_mean - test_scores_std, alpha=0.2)\n",
    "idx_max = np.argmax(test_scores_mean)\n",
    "plt.scatter(param_range[idx_max], test_scores_mean[idx_max],\n",
    "            label=r'Cohen Kappa: ${0:.2f}\\pm{1:.2f}$'.format(\n",
    "                test_scores_mean[idx_max], test_scores_std[idx_max]))\n",
    "\n",
    "plt.title(\"Validation Curve with SMOTE-CART\")\n",
    "plt.xlabel(\"k_neighbors\")\n",
    "plt.ylabel(\"Cohen's kappa\")\n",
    "\n",
    "# make nice plotting\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.get_xaxis().tick_bottom()\n",
    "ax.get_yaxis().tick_left()\n",
    "ax.spines['left'].set_position(('outward', 10))\n",
    "ax.spines['bottom'].set_position(('outward', 10))\n",
    "plt.xlim([1, 10])\n",
    "plt.ylim([0.0, 1.0])\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# # Create a folder to fetch the dataset\n",
    "# iris = load_iris()\n",
    "# X, y = make_imbalance(iris.data, iris.target, ratio={0: 25, 1: 50, 2: 50},\n",
    "#                       random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=RANDOM_STATE)\n",
    "\n",
    "print('Training target statistics: {}'.format(Counter(y_train)))\n",
    "print('Testing target statistics: {}'.format(Counter(y_test)))\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=2, random_state=RANDOM_STATE),\n",
    "                         LinearSVC(random_state=RANDOM_STATE))\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test, pipeline.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# # print(__doc__)\n",
    "\n",
    "# # # Generate the dataset\n",
    "# # X, y = make_classification(n_classes=2, class_sep=2, weights=[0.1, 0.9],\n",
    "# #                            n_informative=3, n_redundant=1, flip_y=0,\n",
    "# #                            n_features=20, n_clusters_per_class=1,\n",
    "# #                            n_samples=200, random_state=10)\n",
    "\n",
    "# # Instanciate a PCA object for the sake of easy visualisation\n",
    "# pca = PCA(n_components=2)\n",
    "# # Fit and transform x to visualise inside a 2D feature space\n",
    "# X_vis = pca.fit_transform(X)\n",
    "\n",
    "# # Apply the random under-sampling\n",
    "# rus = RandomUnderSampler(return_indices=True)\n",
    "# X_resampled, y_resampled, idx_resampled = rus.fit_sample(X, y)\n",
    "# X_res_vis = pca.transform(X_resampled)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# idx_samples_removed = np.setdiff1d(np.arange(X_vis.shape[0]),\n",
    "#                                    idx_resampled)\n",
    "\n",
    "# idx_class_0 = y_resampled == 0\n",
    "# plt.scatter(X_res_vis[idx_class_0, 0], X_res_vis[idx_class_0, 1],\n",
    "#             alpha=.8, label='Class #0')\n",
    "# plt.scatter(X_res_vis[~idx_class_0, 0], X_res_vis[~idx_class_0, 1],\n",
    "#             alpha=.8, label='Class #1')\n",
    "# plt.scatter(X_vis[idx_samples_removed, 0], X_vis[idx_samples_removed, 1],\n",
    "#             alpha=.8, label='Removed samples')\n",
    "\n",
    "# # make nice plotting\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.get_xaxis().tick_bottom()\n",
    "# ax.get_yaxis().tick_left()\n",
    "# ax.spines['left'].set_position(('outward', 10))\n",
    "# ax.spines['bottom'].set_position(('outward', 10))\n",
    "# ax.set_xlim([-6, 6])\n",
    "# ax.set_ylim([-6, 6])\n",
    "\n",
    "# plt.title('Under-sampling using random under-sampling')\n",
    "# plt.legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.under_sampling import (EditedNearestNeighbours,\n",
    "                                     RepeatedEditedNearestNeighbours)\n",
    "\n",
    "# print(__doc__)\n",
    "\n",
    "# # Generate the dataset\n",
    "# X, y = make_classification(n_classes=2, class_sep=1.25, weights=[0.3, 0.7],\n",
    "#                            n_informative=3, n_redundant=1, flip_y=0,\n",
    "#                            n_features=5, n_clusters_per_class=1,\n",
    "#                            n_samples=5000, random_state=10)\n",
    "\n",
    "# Instanciate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Create the samplers\n",
    "enn = EditedNearestNeighbours()\n",
    "renn = RepeatedEditedNearestNeighbours()\n",
    "\n",
    "# Create the classifier\n",
    "knn = KNN(5)\n",
    "\n",
    "# Make the splits\n",
    "X_train, X_test, y_train, y_test = tts(X, y, random_state=42)\n",
    "\n",
    "# Add one transformers and two samplers in the pipeline object\n",
    "pipeline = make_pipeline(pca, enn, renn, knn)\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_hat = pipeline.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tpot = TPOTClassifier(generations=5,population_size=50,verbosity=2,scoring='f1_weighted',n_jobs=48)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_fraud_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.ensemble import BalanceCascade\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = make_classification(n_classes=2, class_sep=2, weights=[0.5, 0.7],\n",
    "                           n_informative=3, n_redundant=1, flip_y=0,\n",
    "                           n_features=80, n_clusters_per_class=1,\n",
    "                           n_samples=200000, random_state=10)\n",
    "\n",
    "# Instanciate a PCA object for the sake of easy visualisation\n",
    "pca = PCA(n_components=2)\n",
    "# Fit and transform x to visualise inside a 2D feature space\n",
    "X_vis = pca.fit_transform(X)\n",
    "\n",
    "# Apply Balance Cascade method\n",
    "bc = BalanceCascade()\n",
    "X_resampled, y_resampled = bc.fit_sample(X, y)\n",
    "X_res_vis = []\n",
    "for X_res in X_resampled:\n",
    "    X_res_vis.append(pca.transform(X_res))\n",
    "\n",
    "# Two subplots, unpack the axes array immediately\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.scatter(X_vis[y == 0, 0], X_vis[y == 0, 1], label=\"Class #0\", alpha=0.5)\n",
    "ax1.scatter(X_vis[y == 1, 0], X_vis[y == 1, 1], label=\"Class #1\", alpha=0.5)\n",
    "ax1.set_title('Original set')\n",
    "\n",
    "ax2.scatter(X_vis[y == 0, 0], X_vis[y == 0, 1], label=\"Class #0\", alpha=0.5)\n",
    "for iy, e in enumerate(X_res_vis):\n",
    "    ax2.scatter(e[y_resampled[iy] == 1, 0], e[y_resampled[iy] == 1, 1],\n",
    "                label=\"Class #1 - set #{}\".format(iy), alpha=0.5)\n",
    "ax2.set_title('Balance cascade')\n",
    "\n",
    "# make nice plotting\n",
    "for ax in (ax1, ax2):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([-6, 8])\n",
    "    ax.set_ylim([-6, 6])\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime as dt\n",
    "#import datetime as datetime\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 100)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.ensemble import EasyEnsemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from imblearn.ensemble import EasyEnsemble\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dataset and create more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv',sep=',')\n",
    "dataset.head()\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def getStdDate(x):\n",
    "    dt_list = x.split('/')\n",
    "    #dt_str = \"0\"+dt_list[0]+\"/\"+\"0\"+dt_list[1]+\"/\"+dt_list[2]\n",
    "    dt_str = dt_list[2]+\"-\"+\"0\"+dt_list[0]+\"-\"+dt_list[1]\n",
    "    datetime_object = dt.datetime.strptime(dt_str,'%Y-%m-%d')\n",
    "    return datetime_object\n",
    "\n",
    "dataset['creationdate'] = dataset['creationdate'].apply(lambda x : getStdDate(x))\n",
    "today= dt.datetime.today().strftime('%Y-%m-%d')\n",
    "today= pd.to_datetime(today)\n",
    "\n",
    "dataset['recency'] = dataset['creationdate'].apply(lambda x:(1/(today-x).days)*365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_count = dataset['bin'].value_counts()\n",
    "bin_count_pdf = bin_count.to_frame()\n",
    "bin_count_pdf['count_of_txn'] = bin_count_pdf['bin']\n",
    "bin_count_pdf['bin'] = bin_count_pdf.index\n",
    "bin_count_pdf.sort_values(by='count_of_txn',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sub = dataset[['bin','fraud']]\n",
    "dataset_sub_pdf = dataset_sub.groupby([\"bin\"]).sum().reset_index()\n",
    "dataset_sub_pdf.sort_values(by='bin').head()\n",
    "bin_fraud_pdf = bin_count_pdf.merge(dataset_sub_pdf, left_on='bin', right_on='bin', how='inner')\n",
    "bin_fraud_pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_fraud_pdf['pc_fraud']=bin_fraud_pdf['fraud']/bin_fraud_pdf['count_of_txn']\n",
    "bin_fraud_pdf.sort_values(by='pc_fraud').head(5)\n",
    "bin_fraud_pdf= bin_fraud_pdf.rename(columns={\"fraud\": \"fraud_count\"})\n",
    "bin_fraud_pdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the newly created features with the original dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.merge(bin_fraud_pdf, left_on='bin', right_on='bin', how='inner')\n",
    "dataset = dataset.drop_duplicates()\n",
    "print(\"Shape after join \",dataset.shape)\n",
    "\n",
    "#drop_list = ['creationdate','bin','count_of_txn','fraud_count']\n",
    "drop_list = ['creationdate','bin','fraud_refusal','declined','count_of_txn','fraud_count','amount','recency','pc_fraud']\n",
    "dataset = dataset.drop(drop_list,axis=1)\n",
    "\n",
    "y_col = 'fraud'\n",
    "X = dataset.drop(y_col,axis=1)\n",
    "#dataset['amount'] = dataset['amount'].apply(lambda x : np.log(x+1))\n",
    "y = dataset['fraud']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows with least variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "sel = VarianceThreshold(threshold=(.98 * (1-.98)))\n",
    "sel.fit_transform(X)\n",
    "X.columns[sel.get_support(indices=True)]\n",
    "vc_list = X.columns[sel.get_support(indices=True)].tolist()\n",
    "print(\"Features selected after variance thresholding \\n\",vc_list)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression,mutual_info_regression,chi2\n",
    "import pandas as pd\n",
    "\n",
    "selector = SelectKBest(chi2, k=5)\n",
    "selector.fit(X, y)\n",
    "X_new = selector.transform(X)\n",
    "X_new.shape\n",
    "X.columns[selector.get_support(indices=True)]\n",
    "chi2_list = X.columns[selector.get_support(indices=True)].tolist()\n",
    "print(\"Chi2 List : \\n\",chi2_list)\n",
    "\n",
    "selector = SelectKBest(f_regression, k=5)\n",
    "selector.fit(X, y)\n",
    "X_new = selector.transform(X)\n",
    "X_new.shape\n",
    "X.columns[selector.get_support(indices=True)]\n",
    "f_classif_list = X.columns[selector.get_support(indices=True)].tolist()\n",
    "print(\"F Classify List: \\n\",f_classif_list)\n",
    "\n",
    "var_sel = vc_list+chi2_list+f_classif_list\n",
    "\n",
    "# X = X[ X.columns.intersection(var_sel)]\n",
    "# y= y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA to get sense of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_sc = scaler.fit_transform(X)\n",
    "\n",
    "# scaler = Normalizer().fit(X)\n",
    "# X = scaler.transform(X)\n",
    "\n",
    "target_names = ['0','1']\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X_sc).transform(X_sc)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "colors = ['navy', 'red']\n",
    "lw = 2\n",
    "for color, i, target_name in zip(colors, [0, 1], target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of Fraud dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Imbalance of the classes\")\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "validation_size = 0.30\n",
    "seed = 13\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=validation_size,random_state=seed)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "#lr = LogisticRegression(n_jobs=10) \n",
    "lr = ExtraTreesClassifier(n_estimators=100)\n",
    "param_grid = {'n_estimators': np.arange(10,500,50)}\n",
    "\n",
    "CV_lr = RandomizedSearchCV(estimator=lr,param_distributions=param_grid,cv=10,scoring='f1_weighted',random_state=seed)\n",
    "#CV_lr = lr\n",
    "\n",
    "CV_lr.fit(X_train_sc, y_train)\n",
    "\n",
    "print (CV_lr.best_params_)\n",
    "\n",
    "lr = CV_lr.best_estimator_\n",
    "lr.fit(X_train_sc, y_train)\n",
    "\n",
    "predictions_train = lr.predict(X_train_sc)\n",
    "print(\"Train Classification Report : \\n\",classification_report(y_train,predictions_train))\n",
    "\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "predictions = lr.predict(X_test_sc)\n",
    "\n",
    "print(\"Train Classification Report : \\n\",classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test Confusion Matrix :\\n \")\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1],title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the dataset is imbalaced one, lets try to the following techinques to see, if we can get higher precision and recall using the following :\n",
    "#### 1) Ramdom Over Sampling\n",
    "#### 2) SMOTE\n",
    "#### 3) Random Under Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Oversampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=0.7)\n",
    "\n",
    "y_train, y_test = np.asarray(y_train),np.asarray(y_test)\n",
    "\n",
    "os =  RandomOverSampler(ratio=0.5)\n",
    "X_train_res, y_train_res = os.fit_sample(X_train, y_train)\n",
    "\n",
    "print (\"Distribution of class labels before resampling {}\".format(Counter(y_train)))\n",
    "print (\"Distribution of class labels after resampling {}\".format(Counter(y_train_res)))\n",
    "\n",
    "#lr = LogisticRegression(n_jobs=10) \n",
    "lr = ExtraTreesClassifier(n_estimators=50)\n",
    "# #param_grid = { 'C': np.arange(1,11,1)}\n",
    "# #CV_lr = RandomizedSearchCV(estimator=lr,param_distributions=param_grid,cv=10,scoring='f1_weighted',random_state=seed)\n",
    "# CV_lr = lr\n",
    "# CV_lr.fit(X_train_sc, y_train)\n",
    "# #print (CV_lr.best_params_)\n",
    "# #lr = CV_lr.best_estimator_\n",
    "\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "predictions_train = lr.predict(X_train_res)\n",
    "print(\"Train Classification Report : \\n\",classification_report(y_train_res,predictions_train))\n",
    "\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "predictions = lr.predict(X_test_sc)\n",
    "\n",
    "print(\"Test Classification Report : \\n\",classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test Confusion Matrix :\\n \")\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1],title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Majority class : 0  /  Minority class : L \n",
    "# Our goal is to maximise precision on the majority class and maximise recall on the minority class.\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "X_smt = X[ X.columns.intersection(f_classif_list)]\n",
    "y_smt = y\n",
    "\n",
    "print(\"Smote data shape\",X_smt.shape)\n",
    "\n",
    "print(\"Smote data shape\",y_smt.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_r, y_smt, train_size=0.7)\n",
    "\n",
    "y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "os_us = SMOTETomek(ratio=0.5,k=5)\n",
    "X_train_res, y_train_res = os_us.fit_sample(X_train, y_train)\n",
    "\n",
    "print (\"Distribution of class labels before resampling {}\".format(Counter(y_train)))\n",
    "print (\"Distribution of class labels after resampling {}\".format(Counter(y_train_res)))\n",
    "\n",
    "#lr = LogisticRegression(n_jobs=10) \n",
    "lr = ExtraTreesClassifier(n_estimators=100)\n",
    "# #param_grid = { 'C': np.arange(1,11,1)}\n",
    "# #CV_lr = RandomizedSearchCV(estimator=lr,param_distributions=param_grid,cv=10,scoring='f1_weighted',random_state=seed)\n",
    "# CV_lr = lr\n",
    "# CV_lr.fit(X_train_sc, y_train)\n",
    "# #print (CV_lr.best_params_)\n",
    "# #lr = CV_lr.best_estimator_\n",
    "\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "predictions_train = lr.predict(X_train_res)\n",
    "print(\"Train Classification Report : \\n\",classification_report(y_train_res,predictions_train))\n",
    "\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "predictions = lr.predict(X_test_sc)\n",
    "\n",
    "print(\"Test Classification Report : \\n\",classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test Confusion Matrix :\\n \")\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1],title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "#y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "us = NearMiss(ratio=0.5, size_ngh=5, version=2)\n",
    "\n",
    "X_train_res, y_train_res = us.fit_sample(X_train, y_train)\n",
    "\n",
    "print (\"Distribution of class labels before resampling {}\".format(Counter(y_train)))\n",
    "print (\"Distribution of class labels after resampling {}\".format(Counter(y_train_res)))\n",
    "\n",
    "#lr = LogisticRegression(n_jobs=10) \n",
    "\n",
    "lr = ExtraTreesClassifier(n_estimators=100)\n",
    "\n",
    "# #param_grid = { 'C': np.arange(1,11,1)}\n",
    "# #CV_lr = RandomizedSearchCV(estimator=lr,param_distributions=param_grid,cv=10,scoring='f1_weighted',random_state=seed)\n",
    "# CV_lr = lr\n",
    "# CV_lr.fit(X_train_sc, y_train)\n",
    "# #print (CV_lr.best_params_)\n",
    "# #lr = CV_lr.best_estimator_\n",
    "\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "predictions_train = lr.predict(X_train_res)\n",
    "\n",
    "print(\"Train Classification Report : \\n\",classification_report(y_train_res,predictions_train))\n",
    "\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "predictions = lr.predict(X_test_sc)\n",
    "\n",
    "print(\"Test Classification Report : \\n\",classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test Confusion Matrix :\\n \")\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1],title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import EasyEnsemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from imblearn.ensemble import EasyEnsemble\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "ens = EasyEnsemble()\n",
    "X_train_res, y_train_res = ens.fit_sample(X_train, y_train)\n",
    "\n",
    "y_pred_proba = np.zeros(len(y_test))\n",
    "\n",
    "for idx in range(len(y_train_res)):\n",
    "    clf_base = ExtraTreesClassifier(n_estimators=100)\n",
    "    grid = {'n_estimators': [50]}\n",
    "    cv = KFold(X_train_res.shape[0], n_folds=5, shuffle=True, random_state=0)\n",
    "    clf = GridSearchCV(clf_base, grid, cv=cv, scoring='f1_weighted')\n",
    "    clf.fit(X_train_res[idx], y_train_res[idx])\n",
    "    y_pred_proba += list(zip(*clf.predict_proba(X_test)))[0]\n",
    "    \n",
    "y_pred_proba = y_pred_proba/len(y_train_res)\n",
    "y_pred = (y_pred_proba > 0.4).astype(int)\n",
    "# #y_pred = y_pred.astype('str')\n",
    "# y_pred[y_pred=='1'] = 0\n",
    "# y_pred[y_pred=='0'] = 1\n",
    "# y_test[y_test=='1'] = 0\n",
    "# y_test[y_test=='0'] = 1\n",
    "\n",
    "print (classification_report(y_test, y_pred))\n",
    "print(\"Test Confusion Matrix :\\n \")\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1],title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "iris = load_iris()\n",
    "# X, y = make_imbalance(iris.data, iris.target, ratio={0: 25, 1: 40, 2: 50},\n",
    "#                       random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "bagging = BaggingClassifier(random_state=0)\n",
    "balanced_bagging = BalancedBaggingClassifier(random_state=0,n_estimators=250,base_estimator=lr)\n",
    "\n",
    "print('Class distribution of the training set: {}'.format(Counter(y_train)))\n",
    "\n",
    "bagging.fit(X_train, y_train)\n",
    "balanced_bagging.fit(X_train, y_train)\n",
    "\n",
    "print('Class distribution of the test set: {}'.format(Counter(y_test)))\n",
    "\n",
    "print('Classification results using a bagging classifier on imbalanced data')\n",
    "y_pred_bagging = bagging.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_pred_bagging))\n",
    "cm_bagging = confusion_matrix(y_test, y_pred_bagging)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_bagging, classes=[0,1],title='Confusion matrix using BaggingClassifier')\n",
    "\n",
    "print('Classification results using a bagging classifier on balanced data')\n",
    "y_pred_balanced_bagging = balanced_bagging.predict(X_test)\n",
    "print(classification_report_imbalanced(y_test, y_pred_balanced_bagging))\n",
    "cm_balanced_bagging = confusion_matrix(y_test, y_pred_balanced_bagging)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_balanced_bagging, classes=[0,1],title='Confusion matrix using BalancedBaggingClassifier')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "balanced_bagging.base_estimator.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)\n",
    "\n",
    "y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
    "\n",
    "sm = SMOTEENN()\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "print (\"Distribution of class labels before resampling {}\".format(Counter(y_train)))\n",
    "print (\"Distribution of class labels after resampling {}\".format(Counter(y_train_res)))\n",
    "\n",
    "#lr = LogisticRegression(n_jobs=10) \n",
    "lr = ExtraTreesClassifier(n_estimators=100)\n",
    "# #param_grid = { 'C': np.arange(1,11,1)}\n",
    "# #CV_lr = RandomizedSearchCV(estimator=lr,param_distributions=param_grid,cv=10,scoring='f1_weighted',random_state=seed)\n",
    "# CV_lr = lr\n",
    "# CV_lr.fit(X_train_sc, y_train)\n",
    "# #print (CV_lr.best_params_)\n",
    "# #lr = CV_lr.best_estimator_\n",
    "\n",
    "lr.fit(X_train_res, y_train_res)\n",
    "\n",
    "predictions_train = lr.predict(X_train_res)\n",
    "print(\"Train Classification Report : \\n\",classification_report(y_train_res,predictions_train))\n",
    "\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "predictions = lr.predict(X_test_sc)\n",
    "\n",
    "print(\"Test Classification Report : \\n\",classification_report(y_test, predictions))\n",
    "\n",
    "print(\"Test Confusion Matrix :\\n \")\n",
    "cnf_matrix = confusion_matrix(y_test, predictions)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1],title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
